loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/lweiren/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/lweiren/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.8f56353af4a709bf5ff0fbc915d8f5b42bfff892cbb6ac98c3c45f481a03c685
Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /home/lweiren/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
cuda memory allocated: 452890112
n_trainable_params: 112937661, n_nontrainable_params: 0
> training arguments:
>>> model_name: aen_bert
>>> dataset: twitter
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f07051534d0>
>>> learning_rate: 2e-05
>>> dropout: 0.1
>>> l2reg: 0.01
>>> num_epoch: 10
>>> batch_size: 16
>>> log_step: 5
>>> embed_dim: 300
>>> hidden_dim: 300
>>> bert_dim: 768
>>> pretrained_bert_name: bert-base-uncased
>>> max_seq_len: 80
>>> polarities_dim: 3
>>> hops: 3
>>> device: cuda
>>> seed: None
>>> valset_ratio: 0
>>> local_context_focus: cdm
>>> SRD: 3
>>> model_class: <class 'models.aen.AEN_BERT'>
>>> dataset_file: {'train': './datasets/acl-14-short-data/train.raw', 'test': './datasets/acl-14-short-data/test.raw'}
>>> inputs_cols: ['text_raw_bert_indices', 'aspect_bert_indices']
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
loss: 0.9890, acc: 0.5625
loss: 1.0615, acc: 0.5625
loss: 1.0305, acc: 0.5792
loss: 1.0404, acc: 0.5563
loss: 1.0367, acc: 0.5475
loss: 1.0465, acc: 0.5312
loss: 1.0394, acc: 0.5268
loss: 1.0408, acc: 0.5234
loss: 1.0348, acc: 0.5194
loss: 1.0290, acc: 0.5175
loss: 1.0271, acc: 0.5102
loss: 1.0192, acc: 0.5094
loss: 1.0108, acc: 0.5192
loss: 1.0048, acc: 0.5250
loss: 0.9961, acc: 0.5292
loss: 0.9877, acc: 0.5328
loss: 0.9849, acc: 0.5309
loss: 0.9820, acc: 0.5340
loss: 0.9700, acc: 0.5414
loss: 0.9649, acc: 0.5456
loss: 0.9549, acc: 0.5518
loss: 0.9484, acc: 0.5545
loss: 0.9432, acc: 0.5543
loss: 0.9492, acc: 0.5536
loss: 0.9465, acc: 0.5570
loss: 0.9422, acc: 0.5611
loss: 0.9356, acc: 0.5644
loss: 0.9324, acc: 0.5674
loss: 0.9236, acc: 0.5724
loss: 0.9190, acc: 0.5746
loss: 0.9204, acc: 0.5734
loss: 0.9166, acc: 0.5730
loss: 0.9121, acc: 0.5769
loss: 0.9094, acc: 0.5794
loss: 0.9076, acc: 0.5807
loss: 0.9049, acc: 0.5830
loss: 0.9014, acc: 0.5828
loss: 0.9005, acc: 0.5839
loss: 0.8973, acc: 0.5862
loss: 0.8948, acc: 0.5863
loss: 0.8918, acc: 0.5875
loss: 0.8866, acc: 0.5908
loss: 0.8888, acc: 0.5898
loss: 0.8866, acc: 0.5915
loss: 0.8858, acc: 0.5917
loss: 0.8836, acc: 0.5921
loss: 0.8806, acc: 0.5941
loss: 0.8811, acc: 0.5935
loss: 0.8823, acc: 0.5929
loss: 0.8815, acc: 0.5938
loss: 0.8775, acc: 0.5961
loss: 0.8774, acc: 0.5959
loss: 0.8759, acc: 0.5965
loss: 0.8749, acc: 0.5965
loss: 0.8705, acc: 0.5991
loss: 0.8688, acc: 0.6000
loss: 0.8654, acc: 0.6013
loss: 0.8632, acc: 0.6030
loss: 0.8612, acc: 0.6036
loss: 0.8584, acc: 0.6050
loss: 0.8570, acc: 0.6055
loss: 0.8560, acc: 0.6062
loss: 0.8538, acc: 0.6081
loss: 0.8504, acc: 0.6105
loss: 0.8486, acc: 0.6115
loss: 0.8477, acc: 0.6119
loss: 0.8470, acc: 0.6114
loss: 0.8443, acc: 0.6132
loss: 0.8451, acc: 0.6125
loss: 0.8442, acc: 0.6134
loss: 0.8419, acc: 0.6151
loss: 0.8398, acc: 0.6158
loss: 0.8389, acc: 0.6166
loss: 0.8373, acc: 0.6166
loss: 0.8352, acc: 0.6182
loss: 0.8339, acc: 0.6184
loss: 0.8350, acc: 0.6183
loss: 0.8326, acc: 0.6188
> val_acc: 0.6214, val_f1: 0.6313
>> saved: state_dict/aen_bert_twitter_val_acc0.6214
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.7325, acc: 0.6250
loss: 0.7410, acc: 0.6111
loss: 0.7496, acc: 0.6205
loss: 0.7299, acc: 0.6382
loss: 0.7171, acc: 0.6458
loss: 0.6921, acc: 0.6616
loss: 0.6768, acc: 0.6728
loss: 0.6686, acc: 0.6795
loss: 0.6607, acc: 0.6889
loss: 0.6613, acc: 0.6862
loss: 0.6617, acc: 0.6898
loss: 0.6615, acc: 0.6907
loss: 0.6582, acc: 0.6982
loss: 0.6632, acc: 0.6957
loss: 0.6676, acc: 0.6951
loss: 0.6656, acc: 0.6970
loss: 0.6671, acc: 0.6972
loss: 0.6699, acc: 0.6938
loss: 0.6646, acc: 0.6968
loss: 0.6649, acc: 0.6970
loss: 0.6578, acc: 0.7019
loss: 0.6544, acc: 0.7024
loss: 0.6518, acc: 0.7050
loss: 0.6465, acc: 0.7080
loss: 0.6412, acc: 0.7107
loss: 0.6479, acc: 0.7093
loss: 0.6495, acc: 0.7076
loss: 0.6515, acc: 0.7082
loss: 0.6501, acc: 0.7088
loss: 0.6493, acc: 0.7085
loss: 0.6468, acc: 0.7070
loss: 0.6485, acc: 0.7075
loss: 0.6472, acc: 0.7077
loss: 0.6499, acc: 0.7049
loss: 0.6475, acc: 0.7065
loss: 0.6429, acc: 0.7095
loss: 0.6466, acc: 0.7065
loss: 0.6463, acc: 0.7073
loss: 0.6454, acc: 0.7068
loss: 0.6447, acc: 0.7092
loss: 0.6460, acc: 0.7077
loss: 0.6443, acc: 0.7087
loss: 0.6454, acc: 0.7088
loss: 0.6445, acc: 0.7095
loss: 0.6471, acc: 0.7079
loss: 0.6497, acc: 0.7061
loss: 0.6503, acc: 0.7067
loss: 0.6506, acc: 0.7063
loss: 0.6490, acc: 0.7080
loss: 0.6484, acc: 0.7093
loss: 0.6466, acc: 0.7111
loss: 0.6455, acc: 0.7109
loss: 0.6453, acc: 0.7116
loss: 0.6454, acc: 0.7114
loss: 0.6441, acc: 0.7133
loss: 0.6420, acc: 0.7144
loss: 0.6415, acc: 0.7152
loss: 0.6402, acc: 0.7152
loss: 0.6421, acc: 0.7147
loss: 0.6431, acc: 0.7143
loss: 0.6414, acc: 0.7155
loss: 0.6383, acc: 0.7166
loss: 0.6366, acc: 0.7180
loss: 0.6369, acc: 0.7173
loss: 0.6344, acc: 0.7188
loss: 0.6345, acc: 0.7192
loss: 0.6319, acc: 0.7208
loss: 0.6323, acc: 0.7209
loss: 0.6339, acc: 0.7213
loss: 0.6345, acc: 0.7206
loss: 0.6371, acc: 0.7191
loss: 0.6373, acc: 0.7192
loss: 0.6372, acc: 0.7198
loss: 0.6370, acc: 0.7207
loss: 0.6365, acc: 0.7208
loss: 0.6369, acc: 0.7206
loss: 0.6381, acc: 0.7197
loss: 0.6374, acc: 0.7195
> val_acc: 0.7197, val_f1: 0.6917
>> saved: state_dict/aen_bert_twitter_val_acc0.7197
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.6005, acc: 0.7292
loss: 0.5002, acc: 0.7891
loss: 0.4922, acc: 0.7788
loss: 0.4999, acc: 0.7812
loss: 0.4775, acc: 0.7880
loss: 0.4811, acc: 0.7924
loss: 0.4875, acc: 0.7898
loss: 0.4907, acc: 0.7862
loss: 0.4890, acc: 0.7849
loss: 0.4891, acc: 0.7852
loss: 0.4950, acc: 0.7830
loss: 0.5028, acc: 0.7856
loss: 0.5066, acc: 0.7847
loss: 0.5110, acc: 0.7858
loss: 0.5060, acc: 0.7902
loss: 0.5022, acc: 0.7949
loss: 0.5077, acc: 0.7892
loss: 0.5056, acc: 0.7905
loss: 0.5069, acc: 0.7910
loss: 0.5007, acc: 0.7940
loss: 0.5187, acc: 0.7840
loss: 0.5194, acc: 0.7824
loss: 0.5226, acc: 0.7804
loss: 0.5212, acc: 0.7839
loss: 0.5191, acc: 0.7825
loss: 0.5180, acc: 0.7837
loss: 0.5186, acc: 0.7843
loss: 0.5148, acc: 0.7862
loss: 0.5182, acc: 0.7854
loss: 0.5222, acc: 0.7838
loss: 0.5198, acc: 0.7839
loss: 0.5168, acc: 0.7864
loss: 0.5193, acc: 0.7864
loss: 0.5226, acc: 0.7861
loss: 0.5206, acc: 0.7865
loss: 0.5161, acc: 0.7886
loss: 0.5140, acc: 0.7910
loss: 0.5152, acc: 0.7912
loss: 0.5172, acc: 0.7895
loss: 0.5162, acc: 0.7901
loss: 0.5155, acc: 0.7906
loss: 0.5172, acc: 0.7888
loss: 0.5168, acc: 0.7890
loss: 0.5174, acc: 0.7890
loss: 0.5202, acc: 0.7870
loss: 0.5185, acc: 0.7878
loss: 0.5204, acc: 0.7865
loss: 0.5220, acc: 0.7852
loss: 0.5261, acc: 0.7832
loss: 0.5279, acc: 0.7823
loss: 0.5285, acc: 0.7826
loss: 0.5284, acc: 0.7832
loss: 0.5301, acc: 0.7821
loss: 0.5326, acc: 0.7812
loss: 0.5369, acc: 0.7782
loss: 0.5400, acc: 0.7770
loss: 0.5385, acc: 0.7787
loss: 0.5420, acc: 0.7778
loss: 0.5456, acc: 0.7760
loss: 0.5473, acc: 0.7756
loss: 0.5467, acc: 0.7762
loss: 0.5470, acc: 0.7764
loss: 0.5463, acc: 0.7764
loss: 0.5479, acc: 0.7750
loss: 0.5496, acc: 0.7728
loss: 0.5512, acc: 0.7717
loss: 0.5523, acc: 0.7708
loss: 0.5518, acc: 0.7707
loss: 0.5496, acc: 0.7726
loss: 0.5494, acc: 0.7721
loss: 0.5502, acc: 0.7716
loss: 0.5496, acc: 0.7722
loss: 0.5490, acc: 0.7726
loss: 0.5490, acc: 0.7719
loss: 0.5489, acc: 0.7718
loss: 0.5513, acc: 0.7707
loss: 0.5512, acc: 0.7704
loss: 0.5520, acc: 0.7700
> val_acc: 0.6590, val_f1: 0.6626
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
loss: 0.6587, acc: 0.7188
loss: 0.5452, acc: 0.8036
loss: 0.5070, acc: 0.7969
loss: 0.4826, acc: 0.8125
loss: 0.4718, acc: 0.8153
loss: 0.4648, acc: 0.8218
loss: 0.4495, acc: 0.8242
loss: 0.4422, acc: 0.8243
loss: 0.4312, acc: 0.8304
loss: 0.4241, acc: 0.8311
loss: 0.4170, acc: 0.8329
loss: 0.4251, acc: 0.8289
loss: 0.4198, acc: 0.8337
loss: 0.4150, acc: 0.8377
loss: 0.4173, acc: 0.8351
loss: 0.4278, acc: 0.8320
loss: 0.4294, acc: 0.8277
loss: 0.4317, acc: 0.8261
loss: 0.4279, acc: 0.8274
loss: 0.4265, acc: 0.8280
loss: 0.4263, acc: 0.8272
loss: 0.4233, acc: 0.8289
loss: 0.4268, acc: 0.8281
loss: 0.4293, acc: 0.8264
loss: 0.4283, acc: 0.8268
loss: 0.4304, acc: 0.8258
loss: 0.4349, acc: 0.8229
loss: 0.4415, acc: 0.8207
loss: 0.4420, acc: 0.8191
loss: 0.4454, acc: 0.8172
loss: 0.4528, acc: 0.8129
loss: 0.4583, acc: 0.8101
loss: 0.4624, acc: 0.8063
loss: 0.4631, acc: 0.8061
loss: 0.4638, acc: 0.8063
loss: 0.4657, acc: 0.8058
loss: 0.4715, acc: 0.8025
loss: 0.4727, acc: 0.8011
loss: 0.4674, acc: 0.8050
loss: 0.4694, acc: 0.8046
loss: 0.4683, acc: 0.8054
loss: 0.4675, acc: 0.8071
loss: 0.4683, acc: 0.8072
loss: 0.4667, acc: 0.8073
loss: 0.4663, acc: 0.8066
loss: 0.4716, acc: 0.8048
loss: 0.4712, acc: 0.8050
loss: 0.4709, acc: 0.8049
loss: 0.4728, acc: 0.8042
loss: 0.4754, acc: 0.8034
loss: 0.4752, acc: 0.8036
loss: 0.4765, acc: 0.8035
loss: 0.4795, acc: 0.8015
loss: 0.4826, acc: 0.8001
loss: 0.4813, acc: 0.8012
loss: 0.4827, acc: 0.7994
loss: 0.4825, acc: 0.7999
loss: 0.4817, acc: 0.8001
loss: 0.4820, acc: 0.8003
loss: 0.4811, acc: 0.8005
loss: 0.4815, acc: 0.8007
loss: 0.4857, acc: 0.7993
loss: 0.4852, acc: 0.7991
loss: 0.4848, acc: 0.7991
loss: 0.4837, acc: 0.7997
loss: 0.4842, acc: 0.7993
loss: 0.4835, acc: 0.7991
loss: 0.4868, acc: 0.7977
loss: 0.4866, acc: 0.7979
loss: 0.4889, acc: 0.7965
loss: 0.4901, acc: 0.7953
loss: 0.4909, acc: 0.7953
loss: 0.4913, acc: 0.7954
loss: 0.4918, acc: 0.7956
loss: 0.4920, acc: 0.7952
loss: 0.4933, acc: 0.7944
loss: 0.4945, acc: 0.7942
loss: 0.4951, acc: 0.7939
> val_acc: 0.7312, val_f1: 0.7051
>> saved: state_dict/aen_bert_twitter_val_acc0.7312
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 4
loss: 0.5323, acc: 0.6875
loss: 0.3939, acc: 0.8333
loss: 0.3736, acc: 0.8580
loss: 0.3628, acc: 0.8633
loss: 0.3915, acc: 0.8542
loss: 0.4448, acc: 0.8293
loss: 0.4180, acc: 0.8427
loss: 0.4130, acc: 0.8438
loss: 0.4141, acc: 0.8476
loss: 0.4030, acc: 0.8478
loss: 0.3989, acc: 0.8493
loss: 0.3896, acc: 0.8549
loss: 0.3879, acc: 0.8566
loss: 0.3976, acc: 0.8561
loss: 0.4000, acc: 0.8539
loss: 0.4084, acc: 0.8512
loss: 0.4102, acc: 0.8503
loss: 0.4134, acc: 0.8459
loss: 0.4077, acc: 0.8496
loss: 0.4011, acc: 0.8529
loss: 0.3988, acc: 0.8540
loss: 0.4058, acc: 0.8514
loss: 0.4097, acc: 0.8480
loss: 0.4222, acc: 0.8421
loss: 0.4204, acc: 0.8409
loss: 0.4192, acc: 0.8408
loss: 0.4192, acc: 0.8411
loss: 0.4186, acc: 0.8424
loss: 0.4182, acc: 0.8422
loss: 0.4152, acc: 0.8442
loss: 0.4149, acc: 0.8440
loss: 0.4125, acc: 0.8450
loss: 0.4119, acc: 0.8447
loss: 0.4102, acc: 0.8453
loss: 0.4056, acc: 0.8472
loss: 0.4099, acc: 0.8455
loss: 0.4085, acc: 0.8460
loss: 0.4096, acc: 0.8461
loss: 0.4085, acc: 0.8472
loss: 0.4097, acc: 0.8469
loss: 0.4135, acc: 0.8461
loss: 0.4126, acc: 0.8462
loss: 0.4154, acc: 0.8448
loss: 0.4158, acc: 0.8443
loss: 0.4159, acc: 0.8450
loss: 0.4183, acc: 0.8435
loss: 0.4205, acc: 0.8433
loss: 0.4216, acc: 0.8419
loss: 0.4204, acc: 0.8426
loss: 0.4230, acc: 0.8407
loss: 0.4261, acc: 0.8376
loss: 0.4293, acc: 0.8369
loss: 0.4300, acc: 0.8372
loss: 0.4304, acc: 0.8367
loss: 0.4318, acc: 0.8363
loss: 0.4316, acc: 0.8356
loss: 0.4318, acc: 0.8354
loss: 0.4320, acc: 0.8359
loss: 0.4346, acc: 0.8344
loss: 0.4354, acc: 0.8338
loss: 0.4355, acc: 0.8337
loss: 0.4343, acc: 0.8344
loss: 0.4329, acc: 0.8350
loss: 0.4358, acc: 0.8339
loss: 0.4358, acc: 0.8337
loss: 0.4363, acc: 0.8332
loss: 0.4366, acc: 0.8329
loss: 0.4378, acc: 0.8318
loss: 0.4423, acc: 0.8308
loss: 0.4440, acc: 0.8295
loss: 0.4465, acc: 0.8276
loss: 0.4481, acc: 0.8267
loss: 0.4480, acc: 0.8267
loss: 0.4470, acc: 0.8270
loss: 0.4483, acc: 0.8261
loss: 0.4483, acc: 0.8265
loss: 0.4489, acc: 0.8268
loss: 0.4496, acc: 0.8264
loss: 0.4519, acc: 0.8252
> val_acc: 0.7023, val_f1: 0.6951
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 5
loss: 0.3501, acc: 0.8625
loss: 0.4164, acc: 0.8625
loss: 0.4096, acc: 0.8500
loss: 0.3965, acc: 0.8562
loss: 0.3811, acc: 0.8550
loss: 0.3900, acc: 0.8500
loss: 0.3730, acc: 0.8536
loss: 0.3701, acc: 0.8562
loss: 0.3552, acc: 0.8611
loss: 0.3517, acc: 0.8625
loss: 0.3530, acc: 0.8648
loss: 0.3559, acc: 0.8667
loss: 0.3584, acc: 0.8663
loss: 0.3686, acc: 0.8634
loss: 0.3748, acc: 0.8608
loss: 0.3798, acc: 0.8586
loss: 0.3778, acc: 0.8566
loss: 0.3721, acc: 0.8569
loss: 0.3718, acc: 0.8579
loss: 0.3700, acc: 0.8581
loss: 0.3703, acc: 0.8583
loss: 0.3754, acc: 0.8557
loss: 0.3739, acc: 0.8571
loss: 0.3744, acc: 0.8557
loss: 0.3789, acc: 0.8530
loss: 0.3749, acc: 0.8543
loss: 0.3778, acc: 0.8532
loss: 0.3762, acc: 0.8558
loss: 0.3742, acc: 0.8573
loss: 0.3770, acc: 0.8558
loss: 0.3854, acc: 0.8516
loss: 0.3887, acc: 0.8500
loss: 0.3878, acc: 0.8508
loss: 0.3851, acc: 0.8518
loss: 0.3837, acc: 0.8521
loss: 0.3831, acc: 0.8514
loss: 0.3808, acc: 0.8524
loss: 0.3785, acc: 0.8526
loss: 0.3776, acc: 0.8535
loss: 0.3824, acc: 0.8522
loss: 0.3836, acc: 0.8515
loss: 0.3844, acc: 0.8506
loss: 0.3844, acc: 0.8509
loss: 0.3842, acc: 0.8494
loss: 0.3888, acc: 0.8475
loss: 0.3891, acc: 0.8476
loss: 0.3910, acc: 0.8468
loss: 0.3946, acc: 0.8443
loss: 0.3975, acc: 0.8418
loss: 0.3994, acc: 0.8410
loss: 0.4047, acc: 0.8380
loss: 0.4059, acc: 0.8377
loss: 0.4085, acc: 0.8366
loss: 0.4095, acc: 0.8359
loss: 0.4124, acc: 0.8345
loss: 0.4129, acc: 0.8348
loss: 0.4138, acc: 0.8355
loss: 0.4132, acc: 0.8364
loss: 0.4123, acc: 0.8371
loss: 0.4105, acc: 0.8377
loss: 0.4112, acc: 0.8363
loss: 0.4123, acc: 0.8357
loss: 0.4140, acc: 0.8345
loss: 0.4151, acc: 0.8334
loss: 0.4155, acc: 0.8327
loss: 0.4162, acc: 0.8326
loss: 0.4159, acc: 0.8330
loss: 0.4184, acc: 0.8325
loss: 0.4194, acc: 0.8315
loss: 0.4184, acc: 0.8318
loss: 0.4164, acc: 0.8326
loss: 0.4180, acc: 0.8318
loss: 0.4188, acc: 0.8317
loss: 0.4188, acc: 0.8313
loss: 0.4197, acc: 0.8308
loss: 0.4206, acc: 0.8306
loss: 0.4214, acc: 0.8302
loss: 0.4233, acc: 0.8295
> val_acc: 0.6532, val_f1: 0.6514
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 6
loss: 0.4072, acc: 0.8125
loss: 0.4228, acc: 0.8333
loss: 0.4641, acc: 0.8080
loss: 0.4319, acc: 0.8191
loss: 0.4379, acc: 0.8125
loss: 0.4104, acc: 0.8297
loss: 0.4000, acc: 0.8327
loss: 0.3949, acc: 0.8381
loss: 0.3797, acc: 0.8452
loss: 0.3809, acc: 0.8444
loss: 0.3669, acc: 0.8507
loss: 0.3612, acc: 0.8496
loss: 0.3614, acc: 0.8506
loss: 0.3587, acc: 0.8514
loss: 0.3500, acc: 0.8581
loss: 0.3467, acc: 0.8600
loss: 0.3452, acc: 0.8594
loss: 0.3440, acc: 0.8588
loss: 0.3531, acc: 0.8544
loss: 0.3523, acc: 0.8535
loss: 0.3533, acc: 0.8528
loss: 0.3479, acc: 0.8555
loss: 0.3450, acc: 0.8586
loss: 0.3438, acc: 0.8598
loss: 0.3441, acc: 0.8589
loss: 0.3463, acc: 0.8561
loss: 0.3542, acc: 0.8526
loss: 0.3552, acc: 0.8530
loss: 0.3555, acc: 0.8533
loss: 0.3561, acc: 0.8540
loss: 0.3561, acc: 0.8543
loss: 0.3598, acc: 0.8530
loss: 0.3606, acc: 0.8525
loss: 0.3625, acc: 0.8517
loss: 0.3636, acc: 0.8513
loss: 0.3641, acc: 0.8495
loss: 0.3685, acc: 0.8475
loss: 0.3666, acc: 0.8479
loss: 0.3688, acc: 0.8479
loss: 0.3706, acc: 0.8477
loss: 0.3708, acc: 0.8468
loss: 0.3733, acc: 0.8460
loss: 0.3751, acc: 0.8452
loss: 0.3770, acc: 0.8439
loss: 0.3761, acc: 0.8438
loss: 0.3748, acc: 0.8436
loss: 0.3749, acc: 0.8440
loss: 0.3748, acc: 0.8431
loss: 0.3749, acc: 0.8435
loss: 0.3759, acc: 0.8436
loss: 0.3777, acc: 0.8433
loss: 0.3777, acc: 0.8444
loss: 0.3778, acc: 0.8445
loss: 0.3775, acc: 0.8441
loss: 0.3753, acc: 0.8449
loss: 0.3753, acc: 0.8450
loss: 0.3778, acc: 0.8438
loss: 0.3782, acc: 0.8439
loss: 0.3778, acc: 0.8444
loss: 0.3771, acc: 0.8445
loss: 0.3738, acc: 0.8462
loss: 0.3716, acc: 0.8471
loss: 0.3705, acc: 0.8475
loss: 0.3719, acc: 0.8470
loss: 0.3723, acc: 0.8468
loss: 0.3739, acc: 0.8467
loss: 0.3738, acc: 0.8469
loss: 0.3755, acc: 0.8462
loss: 0.3786, acc: 0.8450
loss: 0.3835, acc: 0.8426
loss: 0.3855, acc: 0.8415
loss: 0.3866, acc: 0.8417
loss: 0.3885, acc: 0.8410
loss: 0.3899, acc: 0.8403
loss: 0.3898, acc: 0.8402
loss: 0.3893, acc: 0.8410
loss: 0.3910, acc: 0.8407
loss: 0.3927, acc: 0.8405
> val_acc: 0.6749, val_f1: 0.6625
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 7
loss: 0.4183, acc: 0.8333
loss: 0.3835, acc: 0.8438
loss: 0.3362, acc: 0.8750
loss: 0.3127, acc: 0.8819
loss: 0.3106, acc: 0.8886
loss: 0.2877, acc: 0.9018
loss: 0.2861, acc: 0.9015
loss: 0.2817, acc: 0.9030
loss: 0.2657, acc: 0.9084
loss: 0.2622, acc: 0.9102
loss: 0.2550, acc: 0.9104
loss: 0.2468, acc: 0.9127
loss: 0.2485, acc: 0.9117
loss: 0.2469, acc: 0.9127
loss: 0.2443, acc: 0.9144
loss: 0.2548, acc: 0.9111
loss: 0.2634, acc: 0.9066
loss: 0.2618, acc: 0.9055
loss: 0.2731, acc: 0.9026
loss: 0.2755, acc: 0.9005
loss: 0.2786, acc: 0.8999
loss: 0.2852, acc: 0.8970
loss: 0.2909, acc: 0.8933
loss: 0.2911, acc: 0.8941
loss: 0.2931, acc: 0.8938
loss: 0.2908, acc: 0.8965
loss: 0.2897, acc: 0.8976
loss: 0.2857, acc: 0.8986
loss: 0.2867, acc: 0.8960
loss: 0.2873, acc: 0.8940
loss: 0.2863, acc: 0.8934
loss: 0.2887, acc: 0.8916
loss: 0.2887, acc: 0.8915
loss: 0.2871, acc: 0.8925
loss: 0.2896, acc: 0.8913
loss: 0.2942, acc: 0.8887
loss: 0.2965, acc: 0.8863
loss: 0.2973, acc: 0.8860
loss: 0.2960, acc: 0.8873
loss: 0.2963, acc: 0.8879
loss: 0.3014, acc: 0.8864
loss: 0.3057, acc: 0.8852
loss: 0.3109, acc: 0.8835
loss: 0.3130, acc: 0.8827
loss: 0.3136, acc: 0.8817
loss: 0.3174, acc: 0.8805
loss: 0.3233, acc: 0.8785
loss: 0.3243, acc: 0.8784
loss: 0.3250, acc: 0.8791
loss: 0.3255, acc: 0.8798
loss: 0.3258, acc: 0.8792
loss: 0.3255, acc: 0.8794
loss: 0.3231, acc: 0.8812
loss: 0.3226, acc: 0.8811
loss: 0.3223, acc: 0.8812
loss: 0.3222, acc: 0.8808
loss: 0.3252, acc: 0.8796
loss: 0.3268, acc: 0.8780
loss: 0.3274, acc: 0.8786
loss: 0.3274, acc: 0.8781
loss: 0.3265, acc: 0.8785
loss: 0.3269, acc: 0.8784
loss: 0.3295, acc: 0.8778
loss: 0.3323, acc: 0.8768
loss: 0.3332, acc: 0.8760
loss: 0.3360, acc: 0.8739
loss: 0.3380, acc: 0.8727
loss: 0.3369, acc: 0.8735
loss: 0.3399, acc: 0.8726
loss: 0.3405, acc: 0.8725
loss: 0.3413, acc: 0.8727
loss: 0.3419, acc: 0.8719
loss: 0.3424, acc: 0.8714
loss: 0.3419, acc: 0.8713
loss: 0.3433, acc: 0.8708
loss: 0.3438, acc: 0.8707
loss: 0.3441, acc: 0.8708
loss: 0.3445, acc: 0.8710
> val_acc: 0.7110, val_f1: 0.6840
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 8
loss: 0.2368, acc: 0.8750
loss: 0.2491, acc: 0.9018
loss: 0.2386, acc: 0.9219
loss: 0.2542, acc: 0.9007
loss: 0.2604, acc: 0.9006
loss: 0.2730, acc: 0.8958
loss: 0.2780, acc: 0.8887
loss: 0.2689, acc: 0.8919
loss: 0.2785, acc: 0.8869
loss: 0.2881, acc: 0.8843
loss: 0.2919, acc: 0.8846
loss: 0.2947, acc: 0.8849
loss: 0.3035, acc: 0.8810
loss: 0.2947, acc: 0.8862
loss: 0.2914, acc: 0.8872
loss: 0.2977, acc: 0.8856
loss: 0.2991, acc: 0.8834
loss: 0.2972, acc: 0.8843
loss: 0.3017, acc: 0.8845
loss: 0.2991, acc: 0.8860
loss: 0.2987, acc: 0.8866
loss: 0.2976, acc: 0.8884
loss: 0.2960, acc: 0.8890
loss: 0.2965, acc: 0.8889
loss: 0.2957, acc: 0.8888
loss: 0.2990, acc: 0.8868
loss: 0.2993, acc: 0.8859
loss: 0.2972, acc: 0.8873
loss: 0.2965, acc: 0.8882
loss: 0.2988, acc: 0.8873
loss: 0.2953, acc: 0.8886
loss: 0.2903, acc: 0.8917
loss: 0.2918, acc: 0.8912
loss: 0.2915, acc: 0.8926
loss: 0.2891, acc: 0.8935
loss: 0.2878, acc: 0.8937
loss: 0.2854, acc: 0.8946
loss: 0.2851, acc: 0.8947
loss: 0.2849, acc: 0.8955
loss: 0.2875, acc: 0.8950
loss: 0.2921, acc: 0.8933
loss: 0.2913, acc: 0.8934
loss: 0.2938, acc: 0.8930
loss: 0.2917, acc: 0.8934
loss: 0.2913, acc: 0.8930
loss: 0.2910, acc: 0.8932
loss: 0.2924, acc: 0.8930
loss: 0.2918, acc: 0.8935
loss: 0.2914, acc: 0.8939
loss: 0.2916, acc: 0.8942
loss: 0.2930, acc: 0.8929
loss: 0.2938, acc: 0.8928
loss: 0.2933, acc: 0.8929
loss: 0.2930, acc: 0.8928
loss: 0.2914, acc: 0.8932
loss: 0.2914, acc: 0.8931
loss: 0.2921, acc: 0.8923
loss: 0.2938, acc: 0.8913
loss: 0.2941, acc: 0.8913
loss: 0.2972, acc: 0.8897
loss: 0.3003, acc: 0.8876
loss: 0.3011, acc: 0.8870
loss: 0.3018, acc: 0.8872
loss: 0.3015, acc: 0.8874
loss: 0.3026, acc: 0.8874
loss: 0.3037, acc: 0.8869
loss: 0.3029, acc: 0.8874
loss: 0.3025, acc: 0.8880
loss: 0.3023, acc: 0.8880
loss: 0.3024, acc: 0.8878
loss: 0.3032, acc: 0.8876
loss: 0.3022, acc: 0.8876
loss: 0.3035, acc: 0.8867
loss: 0.3036, acc: 0.8869
loss: 0.3052, acc: 0.8863
loss: 0.3081, acc: 0.8854
loss: 0.3096, acc: 0.8853
loss: 0.3128, acc: 0.8840
> val_acc: 0.6344, val_f1: 0.6316
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 9
loss: 0.4597, acc: 0.9375
loss: 0.4697, acc: 0.8229
loss: 0.3696, acc: 0.8693
loss: 0.3467, acc: 0.8867
loss: 0.3427, acc: 0.8750
loss: 0.3227, acc: 0.8798
loss: 0.3228, acc: 0.8831
loss: 0.3184, acc: 0.8837
loss: 0.3197, acc: 0.8857
loss: 0.3048, acc: 0.8913
loss: 0.2916, acc: 0.8958
loss: 0.2970, acc: 0.8940
loss: 0.2882, acc: 0.8975
loss: 0.2797, acc: 0.9025
loss: 0.2752, acc: 0.9040
loss: 0.2727, acc: 0.9038
loss: 0.2751, acc: 0.9035
loss: 0.2673, acc: 0.9070
loss: 0.2603, acc: 0.9093
loss: 0.2600, acc: 0.9089
loss: 0.2558, acc: 0.9103
loss: 0.2565, acc: 0.9104
loss: 0.2583, acc: 0.9105
loss: 0.2548, acc: 0.9116
loss: 0.2550, acc: 0.9122
loss: 0.2502, acc: 0.9147
loss: 0.2491, acc: 0.9146
loss: 0.2470, acc: 0.9145
loss: 0.2494, acc: 0.9145
loss: 0.2494, acc: 0.9140
loss: 0.2493, acc: 0.9131
loss: 0.2521, acc: 0.9123
loss: 0.2512, acc: 0.9130
loss: 0.2541, acc: 0.9111
loss: 0.2596, acc: 0.9094
loss: 0.2594, acc: 0.9105
loss: 0.2649, acc: 0.9071
loss: 0.2640, acc: 0.9079
loss: 0.2642, acc: 0.9074
loss: 0.2615, acc: 0.9085
loss: 0.2606, acc: 0.9089
loss: 0.2590, acc: 0.9090
loss: 0.2590, acc: 0.9085
loss: 0.2646, acc: 0.9065
loss: 0.2637, acc: 0.9070
loss: 0.2656, acc: 0.9062
loss: 0.2659, acc: 0.9053
loss: 0.2660, acc: 0.9049
loss: 0.2711, acc: 0.9025
loss: 0.2728, acc: 0.9009
loss: 0.2743, acc: 0.9004
loss: 0.2789, acc: 0.8987
loss: 0.2798, acc: 0.8980
loss: 0.2807, acc: 0.8976
loss: 0.2812, acc: 0.8976
loss: 0.2817, acc: 0.8972
loss: 0.2816, acc: 0.8972
loss: 0.2821, acc: 0.8975
loss: 0.2808, acc: 0.8982
loss: 0.2811, acc: 0.8982
loss: 0.2800, acc: 0.8987
loss: 0.2813, acc: 0.8983
loss: 0.2808, acc: 0.8979
loss: 0.2828, acc: 0.8975
loss: 0.2842, acc: 0.8972
loss: 0.2847, acc: 0.8969
loss: 0.2857, acc: 0.8967
loss: 0.2873, acc: 0.8964
loss: 0.2891, acc: 0.8953
loss: 0.2893, acc: 0.8954
loss: 0.2894, acc: 0.8951
loss: 0.2911, acc: 0.8936
loss: 0.2925, acc: 0.8930
loss: 0.2950, acc: 0.8917
loss: 0.2968, acc: 0.8907
loss: 0.2966, acc: 0.8905
loss: 0.2973, acc: 0.8903
loss: 0.2992, acc: 0.8892
loss: 0.2981, acc: 0.8899
> val_acc: 0.6879, val_f1: 0.6642
>> test_acc: 0.7312, test_f1: 0.7051
