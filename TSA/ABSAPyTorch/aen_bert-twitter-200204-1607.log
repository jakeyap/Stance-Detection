https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmpa9b0qcpx
copying /tmp/tmpa9b0qcpx to cache at /home/lweiren/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
creating metadata file for /home/lweiren/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
removing temp file /tmp/tmpa9b0qcpx
loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/lweiren/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /tmp/tmp068xy3zu
copying /tmp/tmp068xy3zu to cache at /home/lweiren/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.8f56353af4a709bf5ff0fbc915d8f5b42bfff892cbb6ac98c3c45f481a03c685
creating metadata file for /home/lweiren/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.8f56353af4a709bf5ff0fbc915d8f5b42bfff892cbb6ac98c3c45f481a03c685
removing temp file /tmp/tmp068xy3zu
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/lweiren/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.8f56353af4a709bf5ff0fbc915d8f5b42bfff892cbb6ac98c3c45f481a03c685
Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmpeel0a1yp
copying /tmp/tmpeel0a1yp to cache at /home/lweiren/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
creating metadata file for /home/lweiren/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
removing temp file /tmp/tmpeel0a1yp
loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /home/lweiren/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
cuda memory allocated: 452890112
n_trainable_params: 112937661, n_nontrainable_params: 0
> training arguments:
>>> model_name: aen_bert
>>> dataset: twitter
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x7f8daf7483b0>
>>> learning_rate: 2e-05
>>> dropout: 0.1
>>> l2reg: 0.01
>>> num_epoch: 10
>>> batch_size: 16
>>> log_step: 5
>>> embed_dim: 300
>>> hidden_dim: 300
>>> bert_dim: 768
>>> pretrained_bert_name: bert-base-uncased
>>> max_seq_len: 80
>>> polarities_dim: 3
>>> hops: 3
>>> device: cuda
>>> seed: None
>>> valset_ratio: 0
>>> local_context_focus: cdm
>>> SRD: 3
>>> model_class: <class 'models.aen.AEN_BERT'>
>>> dataset_file: {'train': './datasets/acl-14-short-data/train.raw', 'test': './datasets/acl-14-short-data/test.raw'}
>>> inputs_cols: ['text_raw_bert_indices', 'aspect_bert_indices']
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
loss: 1.3222, acc: 0.3125
loss: 1.2121, acc: 0.3750
loss: 1.1675, acc: 0.4000
loss: 1.1371, acc: 0.3969
loss: 1.1253, acc: 0.4225
loss: 1.1106, acc: 0.4333
loss: 1.1116, acc: 0.4250
loss: 1.1006, acc: 0.4250
loss: 1.0961, acc: 0.4389
loss: 1.0922, acc: 0.4425
loss: 1.0824, acc: 0.4455
loss: 1.0767, acc: 0.4490
loss: 1.0658, acc: 0.4606
loss: 1.0633, acc: 0.4616
loss: 1.0543, acc: 0.4658
loss: 1.0500, acc: 0.4656
loss: 1.0307, acc: 0.4816
loss: 1.0338, acc: 0.4806
loss: 1.0316, acc: 0.4855
loss: 1.0297, acc: 0.4875
loss: 1.0217, acc: 0.4917
loss: 1.0150, acc: 0.4943
loss: 1.0053, acc: 0.5011
loss: 0.9959, acc: 0.5068
loss: 0.9899, acc: 0.5115
loss: 0.9867, acc: 0.5154
loss: 0.9796, acc: 0.5213
loss: 0.9753, acc: 0.5223
loss: 0.9703, acc: 0.5246
loss: 0.9676, acc: 0.5267
loss: 0.9652, acc: 0.5274
loss: 0.9638, acc: 0.5266
loss: 0.9582, acc: 0.5303
loss: 0.9511, acc: 0.5357
loss: 0.9480, acc: 0.5386
loss: 0.9444, acc: 0.5392
loss: 0.9403, acc: 0.5419
loss: 0.9351, acc: 0.5454
loss: 0.9280, acc: 0.5490
loss: 0.9238, acc: 0.5513
loss: 0.9213, acc: 0.5524
loss: 0.9162, acc: 0.5554
loss: 0.9141, acc: 0.5558
loss: 0.9078, acc: 0.5594
loss: 0.9027, acc: 0.5639
loss: 0.9010, acc: 0.5677
loss: 0.8971, acc: 0.5689
loss: 0.8957, acc: 0.5711
loss: 0.8947, acc: 0.5719
loss: 0.8942, acc: 0.5723
loss: 0.8928, acc: 0.5738
loss: 0.8883, acc: 0.5757
loss: 0.8843, acc: 0.5788
loss: 0.8808, acc: 0.5810
loss: 0.8757, acc: 0.5836
loss: 0.8732, acc: 0.5859
loss: 0.8672, acc: 0.5899
loss: 0.8653, acc: 0.5914
loss: 0.8625, acc: 0.5936
loss: 0.8624, acc: 0.5944
loss: 0.8607, acc: 0.5951
loss: 0.8585, acc: 0.5972
loss: 0.8574, acc: 0.5978
loss: 0.8555, acc: 0.5988
loss: 0.8524, acc: 0.6000
loss: 0.8514, acc: 0.6011
loss: 0.8513, acc: 0.6021
loss: 0.8496, acc: 0.6026
loss: 0.8469, acc: 0.6038
loss: 0.8447, acc: 0.6055
loss: 0.8439, acc: 0.6065
loss: 0.8426, acc: 0.6075
loss: 0.8408, acc: 0.6087
loss: 0.8388, acc: 0.6100
loss: 0.8393, acc: 0.6095
loss: 0.8370, acc: 0.6110
loss: 0.8354, acc: 0.6119
loss: 0.8324, acc: 0.6138
> val_acc: 0.6749, val_f1: 0.6389
>> saved: state_dict/aen_bert_twitter_val_acc0.6749
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.6397, acc: 0.6719
loss: 0.5966, acc: 0.7292
loss: 0.5962, acc: 0.7321
loss: 0.5917, acc: 0.7401
loss: 0.5884, acc: 0.7344
loss: 0.6069, acc: 0.7306
loss: 0.6286, acc: 0.7298
loss: 0.6477, acc: 0.7244
loss: 0.6432, acc: 0.7230
loss: 0.6476, acc: 0.7232
loss: 0.6531, acc: 0.7141
loss: 0.6583, acc: 0.7140
loss: 0.6603, acc: 0.7139
loss: 0.6580, acc: 0.7147
loss: 0.6548, acc: 0.7179
loss: 0.6619, acc: 0.7128
loss: 0.6625, acc: 0.7121
loss: 0.6612, acc: 0.7135
loss: 0.6586, acc: 0.7114
loss: 0.6564, acc: 0.7134
loss: 0.6568, acc: 0.7157
loss: 0.6618, acc: 0.7127
loss: 0.6575, acc: 0.7177
loss: 0.6552, acc: 0.7201
loss: 0.6564, acc: 0.7213
loss: 0.6544, acc: 0.7229
loss: 0.6452, acc: 0.7281
loss: 0.6470, acc: 0.7271
loss: 0.6444, acc: 0.7279
loss: 0.6388, acc: 0.7286
loss: 0.6415, acc: 0.7285
loss: 0.6453, acc: 0.7284
loss: 0.6443, acc: 0.7283
loss: 0.6453, acc: 0.7278
loss: 0.6471, acc: 0.7267
loss: 0.6490, acc: 0.7245
loss: 0.6475, acc: 0.7245
loss: 0.6513, acc: 0.7206
loss: 0.6524, acc: 0.7188
loss: 0.6498, acc: 0.7195
loss: 0.6487, acc: 0.7188
loss: 0.6481, acc: 0.7198
loss: 0.6465, acc: 0.7196
loss: 0.6466, acc: 0.7203
loss: 0.6467, acc: 0.7190
loss: 0.6474, acc: 0.7175
loss: 0.6473, acc: 0.7188
loss: 0.6459, acc: 0.7191
loss: 0.6428, acc: 0.7208
loss: 0.6423, acc: 0.7204
loss: 0.6424, acc: 0.7197
loss: 0.6401, acc: 0.7213
loss: 0.6403, acc: 0.7202
loss: 0.6400, acc: 0.7203
loss: 0.6382, acc: 0.7213
loss: 0.6382, acc: 0.7220
loss: 0.6388, acc: 0.7223
loss: 0.6385, acc: 0.7219
loss: 0.6374, acc: 0.7226
loss: 0.6343, acc: 0.7243
loss: 0.6374, acc: 0.7229
loss: 0.6364, acc: 0.7225
loss: 0.6361, acc: 0.7225
loss: 0.6377, acc: 0.7220
loss: 0.6393, acc: 0.7222
loss: 0.6402, acc: 0.7221
loss: 0.6411, acc: 0.7214
loss: 0.6426, acc: 0.7209
loss: 0.6414, acc: 0.7217
loss: 0.6403, acc: 0.7213
loss: 0.6408, acc: 0.7216
loss: 0.6390, acc: 0.7228
loss: 0.6395, acc: 0.7227
loss: 0.6401, acc: 0.7227
loss: 0.6394, acc: 0.7226
loss: 0.6394, acc: 0.7225
loss: 0.6391, acc: 0.7228
loss: 0.6392, acc: 0.7233
> val_acc: 0.6806, val_f1: 0.6794
>> saved: state_dict/aen_bert_twitter_val_acc0.6806
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.4883, acc: 0.8333
loss: 0.5143, acc: 0.8047
loss: 0.5301, acc: 0.7740
loss: 0.5466, acc: 0.7569
loss: 0.4987, acc: 0.7745
loss: 0.5076, acc: 0.7790
loss: 0.5316, acc: 0.7614
loss: 0.5105, acc: 0.7747
loss: 0.5079, acc: 0.7747
loss: 0.5129, acc: 0.7799
loss: 0.5145, acc: 0.7807
loss: 0.5118, acc: 0.7791
loss: 0.5224, acc: 0.7748
loss: 0.5304, acc: 0.7721
loss: 0.5425, acc: 0.7663
loss: 0.5438, acc: 0.7652
loss: 0.5416, acc: 0.7673
loss: 0.5383, acc: 0.7678
loss: 0.5313, acc: 0.7735
loss: 0.5245, acc: 0.7793
loss: 0.5249, acc: 0.7791
loss: 0.5276, acc: 0.7789
loss: 0.5324, acc: 0.7782
loss: 0.5281, acc: 0.7797
loss: 0.5287, acc: 0.7795
loss: 0.5330, acc: 0.7769
loss: 0.5300, acc: 0.7787
loss: 0.5335, acc: 0.7767
loss: 0.5334, acc: 0.7762
loss: 0.5307, acc: 0.7779
loss: 0.5313, acc: 0.7770
loss: 0.5295, acc: 0.7785
loss: 0.5350, acc: 0.7757
loss: 0.5358, acc: 0.7746
loss: 0.5322, acc: 0.7760
loss: 0.5324, acc: 0.7763
loss: 0.5355, acc: 0.7753
loss: 0.5333, acc: 0.7763
loss: 0.5302, acc: 0.7778
loss: 0.5306, acc: 0.7768
loss: 0.5277, acc: 0.7777
loss: 0.5294, acc: 0.7767
loss: 0.5329, acc: 0.7746
loss: 0.5322, acc: 0.7758
loss: 0.5337, acc: 0.7752
loss: 0.5393, acc: 0.7719
loss: 0.5388, acc: 0.7720
loss: 0.5381, acc: 0.7721
loss: 0.5389, acc: 0.7721
loss: 0.5411, acc: 0.7714
loss: 0.5443, acc: 0.7708
loss: 0.5433, acc: 0.7720
loss: 0.5432, acc: 0.7733
loss: 0.5421, acc: 0.7740
loss: 0.5430, acc: 0.7727
loss: 0.5403, acc: 0.7743
loss: 0.5383, acc: 0.7756
loss: 0.5399, acc: 0.7743
loss: 0.5420, acc: 0.7737
loss: 0.5406, acc: 0.7747
loss: 0.5408, acc: 0.7758
loss: 0.5431, acc: 0.7741
loss: 0.5434, acc: 0.7738
loss: 0.5435, acc: 0.7734
loss: 0.5430, acc: 0.7736
loss: 0.5430, acc: 0.7738
loss: 0.5422, acc: 0.7740
loss: 0.5432, acc: 0.7731
loss: 0.5427, acc: 0.7735
loss: 0.5431, acc: 0.7735
loss: 0.5440, acc: 0.7728
loss: 0.5455, acc: 0.7725
loss: 0.5457, acc: 0.7727
loss: 0.5469, acc: 0.7719
loss: 0.5462, acc: 0.7721
loss: 0.5479, acc: 0.7712
loss: 0.5484, acc: 0.7706
loss: 0.5487, acc: 0.7701
> val_acc: 0.7298, val_f1: 0.7234
>> saved: state_dict/aen_bert_twitter_val_acc0.7298
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
loss: 0.4833, acc: 0.8125
loss: 0.4812, acc: 0.8125
loss: 0.4417, acc: 0.8333
loss: 0.3963, acc: 0.8566
loss: 0.3946, acc: 0.8551
loss: 0.3752, acc: 0.8657
loss: 0.3528, acc: 0.8750
loss: 0.3566, acc: 0.8716
loss: 0.3745, acc: 0.8631
loss: 0.3815, acc: 0.8551
loss: 0.3908, acc: 0.8522
loss: 0.3865, acc: 0.8520
loss: 0.3940, acc: 0.8488
loss: 0.4051, acc: 0.8433
loss: 0.4136, acc: 0.8368
loss: 0.4173, acc: 0.8352
loss: 0.4180, acc: 0.8331
loss: 0.4306, acc: 0.8290
loss: 0.4327, acc: 0.8254
loss: 0.4340, acc: 0.8241
loss: 0.4344, acc: 0.8260
loss: 0.4410, acc: 0.8236
loss: 0.4494, acc: 0.8158
loss: 0.4504, acc: 0.8141
loss: 0.4560, acc: 0.8130
loss: 0.4554, acc: 0.8145
loss: 0.4546, acc: 0.8153
loss: 0.4542, acc: 0.8152
loss: 0.4561, acc: 0.8134
loss: 0.4553, acc: 0.8138
loss: 0.4555, acc: 0.8137
loss: 0.4556, acc: 0.8149
loss: 0.4538, acc: 0.8160
loss: 0.4570, acc: 0.8136
loss: 0.4576, acc: 0.8132
loss: 0.4571, acc: 0.8139
loss: 0.4571, acc: 0.8135
loss: 0.4567, acc: 0.8135
loss: 0.4576, acc: 0.8128
loss: 0.4591, acc: 0.8125
loss: 0.4558, acc: 0.8144
loss: 0.4560, acc: 0.8152
loss: 0.4553, acc: 0.8157
loss: 0.4583, acc: 0.8134
loss: 0.4574, acc: 0.8145
loss: 0.4564, acc: 0.8150
loss: 0.4546, acc: 0.8152
loss: 0.4542, acc: 0.8151
loss: 0.4550, acc: 0.8146
loss: 0.4550, acc: 0.8145
loss: 0.4576, acc: 0.8125
loss: 0.4585, acc: 0.8123
loss: 0.4591, acc: 0.8108
loss: 0.4603, acc: 0.8097
loss: 0.4640, acc: 0.8079
loss: 0.4619, acc: 0.8096
loss: 0.4644, acc: 0.8076
loss: 0.4674, acc: 0.8062
loss: 0.4674, acc: 0.8065
loss: 0.4693, acc: 0.8056
loss: 0.4698, acc: 0.8046
loss: 0.4715, acc: 0.8039
loss: 0.4707, acc: 0.8047
loss: 0.4716, acc: 0.8040
loss: 0.4713, acc: 0.8049
loss: 0.4728, acc: 0.8043
loss: 0.4723, acc: 0.8046
loss: 0.4720, acc: 0.8045
loss: 0.4720, acc: 0.8045
loss: 0.4730, acc: 0.8042
loss: 0.4733, acc: 0.8045
loss: 0.4741, acc: 0.8039
loss: 0.4743, acc: 0.8051
loss: 0.4758, acc: 0.8040
loss: 0.4761, acc: 0.8036
loss: 0.4764, acc: 0.8040
loss: 0.4762, acc: 0.8045
loss: 0.4755, acc: 0.8054
> val_acc: 0.6633, val_f1: 0.6618
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 4
loss: 0.4993, acc: 0.8125
loss: 0.4075, acc: 0.8542
loss: 0.3959, acc: 0.8523
loss: 0.3911, acc: 0.8516
loss: 0.4143, acc: 0.8393
loss: 0.3991, acc: 0.8510
loss: 0.3931, acc: 0.8508
loss: 0.4044, acc: 0.8472
loss: 0.4041, acc: 0.8537
loss: 0.4045, acc: 0.8505
loss: 0.3976, acc: 0.8554
loss: 0.4003, acc: 0.8516
loss: 0.3955, acc: 0.8545
loss: 0.3944, acc: 0.8542
loss: 0.3920, acc: 0.8521
loss: 0.3828, acc: 0.8569
loss: 0.3850, acc: 0.8565
loss: 0.3802, acc: 0.8590
loss: 0.3820, acc: 0.8585
loss: 0.3852, acc: 0.8561
loss: 0.3902, acc: 0.8558
loss: 0.3893, acc: 0.8555
loss: 0.3913, acc: 0.8530
loss: 0.3902, acc: 0.8524
loss: 0.3878, acc: 0.8523
loss: 0.3832, acc: 0.8537
loss: 0.3835, acc: 0.8531
loss: 0.3870, acc: 0.8506
loss: 0.3882, acc: 0.8497
loss: 0.3911, acc: 0.8476
loss: 0.3999, acc: 0.8444
loss: 0.4023, acc: 0.8442
loss: 0.4014, acc: 0.8436
loss: 0.4011, acc: 0.8430
loss: 0.4062, acc: 0.8403
loss: 0.4069, acc: 0.8398
loss: 0.4087, acc: 0.8381
loss: 0.4081, acc: 0.8370
loss: 0.4090, acc: 0.8364
loss: 0.4104, acc: 0.8361
loss: 0.4136, acc: 0.8343
loss: 0.4117, acc: 0.8356
loss: 0.4144, acc: 0.8338
loss: 0.4149, acc: 0.8342
loss: 0.4154, acc: 0.8346
loss: 0.4137, acc: 0.8355
loss: 0.4122, acc: 0.8358
loss: 0.4134, acc: 0.8355
loss: 0.4152, acc: 0.8351
loss: 0.4177, acc: 0.8349
loss: 0.4181, acc: 0.8357
loss: 0.4186, acc: 0.8350
loss: 0.4184, acc: 0.8345
loss: 0.4195, acc: 0.8336
loss: 0.4219, acc: 0.8323
loss: 0.4215, acc: 0.8320
loss: 0.4229, acc: 0.8307
loss: 0.4255, acc: 0.8291
loss: 0.4264, acc: 0.8282
loss: 0.4272, acc: 0.8277
loss: 0.4286, acc: 0.8268
loss: 0.4302, acc: 0.8262
loss: 0.4314, acc: 0.8266
loss: 0.4335, acc: 0.8259
loss: 0.4368, acc: 0.8240
loss: 0.4373, acc: 0.8236
loss: 0.4376, acc: 0.8238
loss: 0.4383, acc: 0.8231
loss: 0.4375, acc: 0.8239
loss: 0.4387, acc: 0.8232
loss: 0.4392, acc: 0.8230
loss: 0.4389, acc: 0.8230
loss: 0.4386, acc: 0.8231
loss: 0.4394, acc: 0.8229
loss: 0.4386, acc: 0.8231
loss: 0.4385, acc: 0.8231
loss: 0.4385, acc: 0.8233
loss: 0.4387, acc: 0.8233
loss: 0.4383, acc: 0.8236
> val_acc: 0.7197, val_f1: 0.7081
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 5
loss: 0.2481, acc: 0.9000
loss: 0.3151, acc: 0.8688
loss: 0.3350, acc: 0.8625
loss: 0.3405, acc: 0.8656
loss: 0.3261, acc: 0.8675
loss: 0.3191, acc: 0.8750
loss: 0.3135, acc: 0.8786
loss: 0.3171, acc: 0.8766
loss: 0.3200, acc: 0.8764
loss: 0.3188, acc: 0.8775
loss: 0.3223, acc: 0.8750
loss: 0.3199, acc: 0.8740
loss: 0.3205, acc: 0.8731
loss: 0.3116, acc: 0.8777
loss: 0.3064, acc: 0.8825
loss: 0.3042, acc: 0.8820
loss: 0.3120, acc: 0.8787
loss: 0.3065, acc: 0.8812
loss: 0.3093, acc: 0.8789
loss: 0.3136, acc: 0.8769
loss: 0.3298, acc: 0.8720
loss: 0.3350, acc: 0.8705
loss: 0.3395, acc: 0.8685
loss: 0.3378, acc: 0.8682
loss: 0.3443, acc: 0.8650
loss: 0.3496, acc: 0.8620
loss: 0.3555, acc: 0.8593
loss: 0.3599, acc: 0.8580
loss: 0.3617, acc: 0.8578
loss: 0.3639, acc: 0.8554
loss: 0.3654, acc: 0.8556
loss: 0.3668, acc: 0.8547
loss: 0.3698, acc: 0.8534
loss: 0.3697, acc: 0.8540
loss: 0.3701, acc: 0.8543
loss: 0.3748, acc: 0.8500
loss: 0.3765, acc: 0.8493
loss: 0.3829, acc: 0.8461
loss: 0.3847, acc: 0.8446
loss: 0.3861, acc: 0.8444
loss: 0.3878, acc: 0.8421
loss: 0.3889, acc: 0.8417
loss: 0.3883, acc: 0.8427
loss: 0.3848, acc: 0.8449
loss: 0.3841, acc: 0.8450
loss: 0.3828, acc: 0.8457
loss: 0.3826, acc: 0.8447
loss: 0.3818, acc: 0.8458
loss: 0.3859, acc: 0.8449
loss: 0.3863, acc: 0.8442
loss: 0.3882, acc: 0.8439
loss: 0.3894, acc: 0.8430
loss: 0.3901, acc: 0.8429
loss: 0.3936, acc: 0.8407
loss: 0.3939, acc: 0.8405
loss: 0.3931, acc: 0.8402
loss: 0.3940, acc: 0.8397
loss: 0.3932, acc: 0.8399
loss: 0.3977, acc: 0.8386
loss: 0.3977, acc: 0.8385
loss: 0.3972, acc: 0.8387
loss: 0.3957, acc: 0.8393
loss: 0.3962, acc: 0.8395
loss: 0.3951, acc: 0.8402
loss: 0.3978, acc: 0.8390
loss: 0.4007, acc: 0.8377
loss: 0.4032, acc: 0.8360
loss: 0.4020, acc: 0.8368
loss: 0.4039, acc: 0.8368
loss: 0.4073, acc: 0.8348
loss: 0.4080, acc: 0.8347
loss: 0.4069, acc: 0.8351
loss: 0.4054, acc: 0.8361
loss: 0.4043, acc: 0.8365
loss: 0.4026, acc: 0.8370
loss: 0.4047, acc: 0.8365
loss: 0.4059, acc: 0.8360
loss: 0.4050, acc: 0.8369
> val_acc: 0.6850, val_f1: 0.6681
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 6
loss: 0.2777, acc: 0.9062
loss: 0.2401, acc: 0.9236
loss: 0.2521, acc: 0.9196
loss: 0.2794, acc: 0.9145
loss: 0.2811, acc: 0.9167
loss: 0.3061, acc: 0.9030
loss: 0.3024, acc: 0.8952
loss: 0.3178, acc: 0.8894
loss: 0.3091, acc: 0.8949
loss: 0.3032, acc: 0.8967
loss: 0.3058, acc: 0.8958
loss: 0.3054, acc: 0.8941
loss: 0.2985, acc: 0.8955
loss: 0.2934, acc: 0.8958
loss: 0.2987, acc: 0.8944
loss: 0.3069, acc: 0.8916
loss: 0.3118, acc: 0.8884
loss: 0.3138, acc: 0.8855
loss: 0.3112, acc: 0.8850
loss: 0.3122, acc: 0.8851
loss: 0.3205, acc: 0.8774
loss: 0.3252, acc: 0.8744
loss: 0.3239, acc: 0.8745
loss: 0.3329, acc: 0.8708
loss: 0.3357, acc: 0.8700
loss: 0.3379, acc: 0.8692
loss: 0.3347, acc: 0.8703
loss: 0.3357, acc: 0.8687
loss: 0.3386, acc: 0.8668
loss: 0.3423, acc: 0.8658
loss: 0.3424, acc: 0.8661
loss: 0.3441, acc: 0.8640
loss: 0.3415, acc: 0.8651
loss: 0.3393, acc: 0.8665
loss: 0.3397, acc: 0.8660
loss: 0.3472, acc: 0.8631
loss: 0.3488, acc: 0.8624
loss: 0.3509, acc: 0.8611
loss: 0.3519, acc: 0.8608
loss: 0.3530, acc: 0.8615
loss: 0.3552, acc: 0.8606
loss: 0.3559, acc: 0.8606
loss: 0.3575, acc: 0.8598
loss: 0.3585, acc: 0.8593
loss: 0.3602, acc: 0.8588
loss: 0.3576, acc: 0.8600
loss: 0.3569, acc: 0.8600
loss: 0.3553, acc: 0.8604
loss: 0.3537, acc: 0.8614
loss: 0.3533, acc: 0.8614
loss: 0.3538, acc: 0.8605
loss: 0.3540, acc: 0.8605
loss: 0.3541, acc: 0.8608
loss: 0.3555, acc: 0.8599
loss: 0.3571, acc: 0.8588
loss: 0.3592, acc: 0.8580
loss: 0.3604, acc: 0.8567
loss: 0.3619, acc: 0.8562
loss: 0.3613, acc: 0.8563
loss: 0.3628, acc: 0.8558
loss: 0.3614, acc: 0.8563
loss: 0.3615, acc: 0.8566
loss: 0.3632, acc: 0.8563
loss: 0.3642, acc: 0.8560
loss: 0.3643, acc: 0.8559
loss: 0.3646, acc: 0.8558
loss: 0.3662, acc: 0.8548
loss: 0.3657, acc: 0.8547
loss: 0.3666, acc: 0.8548
loss: 0.3695, acc: 0.8532
loss: 0.3711, acc: 0.8526
loss: 0.3726, acc: 0.8524
loss: 0.3734, acc: 0.8520
loss: 0.3727, acc: 0.8526
loss: 0.3719, acc: 0.8536
loss: 0.3712, acc: 0.8537
loss: 0.3710, acc: 0.8542
loss: 0.3712, acc: 0.8536
> val_acc: 0.7110, val_f1: 0.6731
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 7
loss: 0.1862, acc: 0.9583
loss: 0.2184, acc: 0.9453
loss: 0.2137, acc: 0.9327
loss: 0.2144, acc: 0.9340
loss: 0.2155, acc: 0.9321
loss: 0.2242, acc: 0.9308
loss: 0.2238, acc: 0.9318
loss: 0.2320, acc: 0.9260
loss: 0.2399, acc: 0.9186
loss: 0.2480, acc: 0.9141
loss: 0.2464, acc: 0.9163
loss: 0.2456, acc: 0.9181
loss: 0.2456, acc: 0.9177
loss: 0.2507, acc: 0.9118
loss: 0.2573, acc: 0.9058
loss: 0.2614, acc: 0.9046
loss: 0.2593, acc: 0.9066
loss: 0.2619, acc: 0.9062
loss: 0.2644, acc: 0.9052
loss: 0.2637, acc: 0.9050
loss: 0.2666, acc: 0.9041
loss: 0.2667, acc: 0.9034
loss: 0.2712, acc: 0.9010
loss: 0.2700, acc: 0.9015
loss: 0.2684, acc: 0.9024
loss: 0.2713, acc: 0.9019
loss: 0.2730, acc: 0.9008
loss: 0.2703, acc: 0.9026
loss: 0.2683, acc: 0.9038
loss: 0.2709, acc: 0.9024
loss: 0.2718, acc: 0.9024
loss: 0.2726, acc: 0.9031
loss: 0.2802, acc: 0.8992
loss: 0.2821, acc: 0.8977
loss: 0.2882, acc: 0.8945
loss: 0.2922, acc: 0.8919
loss: 0.2914, acc: 0.8924
loss: 0.2947, acc: 0.8910
loss: 0.2980, acc: 0.8899
loss: 0.3003, acc: 0.8883
loss: 0.3015, acc: 0.8870
loss: 0.3021, acc: 0.8861
loss: 0.3004, acc: 0.8870
loss: 0.3000, acc: 0.8876
loss: 0.3022, acc: 0.8868
loss: 0.3066, acc: 0.8849
loss: 0.3070, acc: 0.8855
loss: 0.3100, acc: 0.8842
loss: 0.3119, acc: 0.8830
loss: 0.3129, acc: 0.8826
loss: 0.3140, acc: 0.8814
loss: 0.3159, acc: 0.8806
loss: 0.3141, acc: 0.8814
loss: 0.3138, acc: 0.8820
loss: 0.3119, acc: 0.8830
loss: 0.3115, acc: 0.8829
loss: 0.3131, acc: 0.8827
loss: 0.3151, acc: 0.8828
loss: 0.3141, acc: 0.8837
loss: 0.3160, acc: 0.8832
loss: 0.3165, acc: 0.8824
loss: 0.3163, acc: 0.8827
loss: 0.3190, acc: 0.8822
loss: 0.3204, acc: 0.8813
loss: 0.3229, acc: 0.8806
loss: 0.3246, acc: 0.8807
loss: 0.3249, acc: 0.8806
loss: 0.3256, acc: 0.8798
loss: 0.3244, acc: 0.8803
loss: 0.3243, acc: 0.8798
loss: 0.3266, acc: 0.8782
loss: 0.3280, acc: 0.8774
loss: 0.3298, acc: 0.8769
loss: 0.3315, acc: 0.8753
loss: 0.3310, acc: 0.8757
loss: 0.3329, acc: 0.8755
loss: 0.3341, acc: 0.8745
loss: 0.3364, acc: 0.8732
> val_acc: 0.6792, val_f1: 0.6591
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 8
loss: 0.3078, acc: 0.8750
loss: 0.2938, acc: 0.8750
loss: 0.2620, acc: 0.9010
loss: 0.2443, acc: 0.9044
loss: 0.2464, acc: 0.9091
loss: 0.2270, acc: 0.9144
loss: 0.2489, acc: 0.9062
loss: 0.2914, acc: 0.8919
loss: 0.3073, acc: 0.8869
loss: 0.3057, acc: 0.8856
loss: 0.3125, acc: 0.8822
loss: 0.3080, acc: 0.8838
loss: 0.3094, acc: 0.8831
loss: 0.3104, acc: 0.8834
loss: 0.3025, acc: 0.8880
loss: 0.2949, acc: 0.8920
loss: 0.2880, acc: 0.8948
loss: 0.2816, acc: 0.8973
loss: 0.2892, acc: 0.8954
loss: 0.2944, acc: 0.8924
loss: 0.2941, acc: 0.8915
loss: 0.2928, acc: 0.8919
loss: 0.2948, acc: 0.8934
loss: 0.2970, acc: 0.8937
loss: 0.2971, acc: 0.8934
loss: 0.2972, acc: 0.8932
loss: 0.2949, acc: 0.8925
loss: 0.2934, acc: 0.8928
loss: 0.2944, acc: 0.8922
loss: 0.2906, acc: 0.8937
loss: 0.2875, acc: 0.8956
loss: 0.2877, acc: 0.8945
loss: 0.2883, acc: 0.8931
loss: 0.2867, acc: 0.8937
loss: 0.2819, acc: 0.8961
loss: 0.2857, acc: 0.8958
loss: 0.2852, acc: 0.8963
loss: 0.2843, acc: 0.8964
loss: 0.2864, acc: 0.8955
loss: 0.2867, acc: 0.8950
loss: 0.2884, acc: 0.8942
loss: 0.2927, acc: 0.8931
loss: 0.2950, acc: 0.8921
loss: 0.2989, acc: 0.8894
loss: 0.2981, acc: 0.8899
loss: 0.2998, acc: 0.8890
loss: 0.2984, acc: 0.8904
loss: 0.2969, acc: 0.8900
loss: 0.3024, acc: 0.8879
loss: 0.3047, acc: 0.8879
loss: 0.3063, acc: 0.8872
loss: 0.3108, acc: 0.8847
loss: 0.3112, acc: 0.8841
loss: 0.3131, acc: 0.8834
loss: 0.3156, acc: 0.8828
loss: 0.3149, acc: 0.8827
loss: 0.3141, acc: 0.8832
loss: 0.3162, acc: 0.8824
loss: 0.3174, acc: 0.8818
loss: 0.3170, acc: 0.8817
loss: 0.3173, acc: 0.8818
loss: 0.3195, acc: 0.8809
loss: 0.3201, acc: 0.8812
loss: 0.3216, acc: 0.8811
loss: 0.3204, acc: 0.8818
loss: 0.3206, acc: 0.8813
loss: 0.3197, acc: 0.8816
loss: 0.3176, acc: 0.8828
loss: 0.3167, acc: 0.8830
loss: 0.3155, acc: 0.8831
loss: 0.3153, acc: 0.8832
loss: 0.3159, acc: 0.8832
loss: 0.3151, acc: 0.8831
loss: 0.3161, acc: 0.8825
loss: 0.3178, acc: 0.8816
loss: 0.3203, acc: 0.8798
loss: 0.3217, acc: 0.8793
loss: 0.3219, acc: 0.8795
> val_acc: 0.6835, val_f1: 0.6652
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 9
loss: 0.1919, acc: 1.0000
loss: 0.1841, acc: 0.9688
loss: 0.1818, acc: 0.9659
loss: 0.2007, acc: 0.9492
loss: 0.1888, acc: 0.9464
loss: 0.2017, acc: 0.9375
loss: 0.2059, acc: 0.9355
loss: 0.1927, acc: 0.9375
loss: 0.1962, acc: 0.9360
loss: 0.1928, acc: 0.9361
loss: 0.1987, acc: 0.9289
loss: 0.2006, acc: 0.9275
loss: 0.2027, acc: 0.9273
loss: 0.2089, acc: 0.9242
loss: 0.2085, acc: 0.9234
loss: 0.2174, acc: 0.9211
loss: 0.2341, acc: 0.9144
loss: 0.2412, acc: 0.9128
loss: 0.2436, acc: 0.9107
loss: 0.2471, acc: 0.9102
loss: 0.2551, acc: 0.9078
loss: 0.2562, acc: 0.9068
loss: 0.2544, acc: 0.9065
loss: 0.2524, acc: 0.9073
loss: 0.2506, acc: 0.9081
loss: 0.2499, acc: 0.9092
loss: 0.2498, acc: 0.9089
loss: 0.2576, acc: 0.9062
loss: 0.2630, acc: 0.9034
loss: 0.2594, acc: 0.9054
loss: 0.2570, acc: 0.9065
loss: 0.2559, acc: 0.9054
loss: 0.2531, acc: 0.9068
loss: 0.2513, acc: 0.9070
loss: 0.2486, acc: 0.9086
loss: 0.2503, acc: 0.9091
loss: 0.2584, acc: 0.9061
loss: 0.2590, acc: 0.9062
loss: 0.2602, acc: 0.9048
loss: 0.2636, acc: 0.9034
loss: 0.2624, acc: 0.9045
loss: 0.2618, acc: 0.9047
loss: 0.2633, acc: 0.9034
loss: 0.2650, acc: 0.9031
loss: 0.2636, acc: 0.9041
loss: 0.2623, acc: 0.9049
loss: 0.2622, acc: 0.9045
loss: 0.2616, acc: 0.9047
loss: 0.2625, acc: 0.9043
loss: 0.2617, acc: 0.9042
loss: 0.2641, acc: 0.9021
loss: 0.2650, acc: 0.9021
loss: 0.2666, acc: 0.9018
loss: 0.2700, acc: 0.9001
loss: 0.2697, acc: 0.8994
loss: 0.2729, acc: 0.8983
loss: 0.2749, acc: 0.8972
loss: 0.2762, acc: 0.8969
loss: 0.2791, acc: 0.8963
loss: 0.2816, acc: 0.8957
loss: 0.2826, acc: 0.8949
loss: 0.2862, acc: 0.8936
loss: 0.2902, acc: 0.8927
loss: 0.2908, acc: 0.8920
loss: 0.2905, acc: 0.8921
loss: 0.2888, acc: 0.8926
loss: 0.2887, acc: 0.8926
loss: 0.2895, acc: 0.8914
loss: 0.2912, acc: 0.8902
loss: 0.2913, acc: 0.8902
loss: 0.2914, acc: 0.8901
loss: 0.2906, acc: 0.8906
loss: 0.2918, acc: 0.8901
loss: 0.2940, acc: 0.8892
loss: 0.2972, acc: 0.8875
loss: 0.2997, acc: 0.8860
loss: 0.2989, acc: 0.8863
loss: 0.2986, acc: 0.8863
loss: 0.2982, acc: 0.8868
> val_acc: 0.6792, val_f1: 0.6481
>> test_acc: 0.7298, test_f1: 0.7234
